{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forming clusters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial idea is to cluster all the stands according to their similarity and then to form own surrogate for every cluster. That of course rises somes questions:\n",
    "- what is the similarity measure?\n",
    "- what is good cluster size?\n",
    "- how do use surrogates in the end?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because clusters and then also surrogates must be created automatically we need some way to measure and compare different clusterings and surrogates. Best way to do that would be feeding the right away in to the optimization and then see how they compare between each other and the solution in the paper. Then we just would need the optimization procedure first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Would it be possible to make a neural network out of the entire problem, so that input would be the same than with the optimization problems already formulated and the output as all the objective functions?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So actually we just would be writing the entire problem again..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But if we input there all the optimun set of all the objective functions and great number of other solutions, would we get out something useful and maybe unexpected?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At least it could be worth trying!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(str(7**29666))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At least there is a possibility to generate quite big datasets (number before is the length of number of possible combinations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Back to reality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though all the previous ideas would be great to try some day, after talking with Jussi it's maybe still a better idea to just form the cluster surrogate and always choose one (virtual) sample to represent entire cluster in the optimization. That way the optimization doesn't have to be altered much and I can focus more on just executing. So clustering it is!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierarchical clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    " %matplotlib inline\n",
    "import seaborn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage, cophenet\n",
    "from scipy.spatial.distance import pdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.join(os.getcwd(), '../boreal_data')\n",
    "\n",
    "carbon = pd.read_csv(os.path.join(data_dir, 'Carbon_storage.csv'))\n",
    "HA = pd.read_csv(os.path.join(data_dir, 'Combined_HA.csv'))\n",
    "deadwood = pd.read_csv(os.path.join(data_dir, 'Deadwood_volume.csv'))\n",
    "revenue = pd.read_csv(os.path.join(data_dir, 'Timber_revenues.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = carbon.copy()\n",
    "X1[carbon.isnull()] = np.nanmin(carbon.values) - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cosine metric is used, because we want to ignore the size of stands and prefer their similarity in different ways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z100 = linkage(X1[:100], metric='cosine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "c100, coph_dists = cophenet(Z100, pdist(X1[:100]))\n",
    "c100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cophenet distance is quite close to 1 so there is no need to be worried (?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "pylab.rcParams['figure.figsize'] = (15,9)\n",
    "plt.figure()\n",
    "dendrogram(Z100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, this works with small data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now question: What is this green cluster?!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import fcluster\n",
    "clusters = fcluster(Z100, 0.14,criterion='distance')\n",
    "clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "carbon[:100][clusters==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "carbon[:100][clusters==2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "carbon[:100][clusters==3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That looks quite great already!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is just one problem: now we assigned Nan-values to be smalles value - 1. This means Nan:s are not a big difference when compared to other values in the dataset -> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.nanmin(carbon.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.nanmax(carbon.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, differences between 'valid' data points are much greater than between 'valid' points and points with Nan-values. So it would make sense to assign much different values for Nan:s. That would also automatically connect all the Nan-including lines to the same clusters. Of course another option is to run this clustering separately for all the lines with Nan:s and all the lines without Nan:s. I am just not sure if assigning greatly different values is more efficient or more general than doing this separately. This should be studied!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare some timings with different sized datasets and clustering methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hierarchical clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "Z100 = linkage(X1[:100], metric='cosine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "Z1000 = linkage(X1[:1000], metric='cosine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "Z10000 = linkage(X1[:10000], metric='cosine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "Z20000 = linkage(X1[:20000], metric='cosine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "Zall = linkage(X1, metric='cosine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "pylab.rcParams['figure.figsize'] = (15,9)\n",
    "plt.figure()\n",
    "dendrogram(Zall, truncate_mode='lastp', p=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import fcluster\n",
    "clusters_all = fcluster(Zall, 50 ,criterion='maxclust')\n",
    "clusters_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = 1\n",
    "print(len(carbon[clusters_all==ind]))\n",
    "carbon[clusters_all==ind][:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "29666*0.35"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It was said that 35% of stands were simulated. Would all stands belonging to the first cluster be those?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's also try hierarchical clustering by assigning much worse values for Nan.s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = carbon.copy()\n",
    "X2[carbon.isnull()] = np.nanmin(carbon.values) - np.nanmax(carbon.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "Zall_diff = linkage(X2, metric='cosine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "pylab.rcParams['figure.figsize'] = (15,9)\n",
    "plt.figure()\n",
    "dendrogram(Zall_diff, truncate_mode='lastp', p=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import fcluster\n",
    "clusters_diff = fcluster(Zall_diff, 50 ,criterion='maxclust')\n",
    "clusters_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = 49\n",
    "print(len(carbon[clusters_diff==ind]))\n",
    "carbon[clusters_diff==ind][:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = 5568\n",
    "((clusters_all==1)[:ind]==(clusters_diff==49)[:ind]).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = 6653\n",
    "((clusters_all==1)[ind:]==(clusters_diff==49)[ind:]).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "(clusters_all==1)[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "(clusters_diff==49)[ind]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.vq import kmeans,vq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "data100 = X1[:100]\n",
    "centroids100, _ = kmeans(data100, 50)\n",
    "idx100,  _ = vq(data100, centroids100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "data1000 = X1[:1000]\n",
    "centroids1000, _ = kmeans(data1000, 50)\n",
    "idx1000,  _ = vq(data1000, centroids1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "data10000 = X1[:10000]\n",
    "centroids10000, _ = kmeans(data10000, 50)\n",
    "idx10000,  _ = vq(data10000, centroids10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "data_all = X1\n",
    "centroidsall, _ = kmeans(data_all, 50)\n",
    "idxall,  _ = vq(data_all, centroidsall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem is, it is not possible to define cosine distance using scipy or sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kmeans import kmeans, randomsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "randomcenters = randomsample(data_all.values, 50)\n",
    "centers, xtoc, dist = kmeans(data_all.values, randomcenters, delta=.001, maxiter=100, metric='cosine', verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot = 0\n",
    "for i in range(50):\n",
    "    tot += sum(xtoc==i)\n",
    "    print(sum(xtoc==i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timing results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-means is remarkably faster than hierarchical clustering. Its weakness is still in the number of clusters.\n",
    "I dont know how to overcome this reliably."
   ]
  }
 ],
 "metadata": {
  "git": {
   "suppress_outputs": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
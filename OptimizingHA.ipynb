{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing HA separately"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There were greatest differences in HA objective values when compared results with and without surrogates. Thats why I would like to study this objective more thoroughly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    " %matplotlib inline\n",
    "import seaborn\n",
    "import matplotlib.pyplot as plt\n",
    "from kmeans import kmeans, randomsample\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "from BorealWeights import BorealWeightedProblem\n",
    "from pyomo.opt import SolverFactory\n",
    "from gradutil import *\n",
    "seed = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now form the clusters by only using HA values, so we can see if the original problem was in the cluster forming part, or if there is something more peculiar in this HA objective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "data_dir = os.path.join(os.getcwd(), '../boreal_data')\n",
    "HA = pd.read_csv(os.path.join(data_dir, 'Combined_HA.csv'))\n",
    "X = HA.values\n",
    "X[HA.isnull()] = np.nanmin(HA) - np.nanmax(HA)\n",
    "randomcenters = randomsample(X, 50)\n",
    "centers, xtoc, dist = kmeans(X,\n",
    "                             randomcenters,\n",
    "                             delta=.00001,\n",
    "                             maxiter=100,\n",
    "                             metric='cosine',\n",
    "                             verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "C = centers.copy()\n",
    "weights = np.array([sum(xtoc==i) for i in range(len(C))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "clustProblemHA = BorealWeightedProblem(C,weights)\n",
    "opt = SolverFactory('glpk')\n",
    "resClustHA = opt.solve(ClustProblemHA.model, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "HASurrogateList = res_to_list(clustProblemHA.model)\n",
    "resultSurrogateHA = cluster_to_value(C, HASurrogateList, weights)\n",
    "print(\"(iv) Combined Habitat {:.0f}\".format(resultSurrogateHA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultOriginHA = clusters_to_origin(X, xtoc, HASurrogateList)\n",
    "print(\"(iv) Combined Habitat {:.0f}\".format(resultOriginHA))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the original optimization the result was:\n",
    "- (iv) Combined Habitat 10327\n",
    "\n",
    "Which is exactly the same than here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this I  conclude, that the problem is clustering when using all the objectives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The solution could be normalizing all the objectives to 0-1 scale, so there would be no weighting differences."
   ]
  }
 ],
 "metadata": {
  "git": {
   "suppress_outputs": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do the same clusters go with another objective?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do everything the same way than before, but use different objective function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    " %matplotlib inline\n",
    "import seaborn\n",
    "import matplotlib.pyplot as plt\n",
    "from kmeans import kmeans, randomsample\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "from BorealWeights import BorealWeightedProblem\n",
    "from pyomo.opt import SolverFactory\n",
    "from gradutil import *\n",
    "seed = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "data_dir = os.path.join(os.getcwd(), '../boreal_data')\n",
    "carbon = pd.read_csv(os.path.join(data_dir, 'Carbon_storage.csv'))\n",
    "X = carbon.values\n",
    "X[carbon.isnull()] = np.nanmin(carbon) - np.nanmax(carbon)\n",
    "randomcenters = randomsample(X, 50)\n",
    "centers, xtoc, dist = kmeans(X,\n",
    "                             randomcenters,\n",
    "                             delta=.00001,\n",
    "                             maxiter=100,\n",
    "                             metric='cosine',\n",
    "                             verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "C = centers.copy()\n",
    "weights = np.array([sum(xtoc==i) for i in range(len(C))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just noticed that I must check if the centers are averages of all the units in the cluster. I am not sure how the cosine distance affects that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "avs = np.array([np.array(X[xtoc==ind].mean(axis=0)) for ind in range(len(C))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C == avs\n",
    "C.round() == avs.round()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I would say this is a bit weird again. I would have assumed that all are either True or False, not mixed up."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check this also! Is there something wrong with k-means?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's still pretend everything is ok and proceed to the test we planned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.join(os.getcwd(), '../boreal_data')\n",
    "revenues = pd.read_csv(os.path.join(data_dir, 'Timber_revenues.csv'))\n",
    "Xr = revenues.values\n",
    "Xr[revenues.isnull()] = np.nanmin(revenues) - np.nanmax(revenues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cr = np.array([np.array(Xr[xtoc==ind].mean(axis=0)) for ind in range(len(C))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ClustProblemRev = BorealWeightedProblem(Cr,weights)\n",
    "opt = SolverFactory('glpk')\n",
    "resRev = opt.solve(ClustProblemRev.model, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "rev_list = res_to_list(ClustProblemRev.model)\n",
    "rev_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim_result_surrogate_rev = sum([Cr[ind,int(rev_list[ind])]*weights[ind] for ind in range(len(rev_list))])\n",
    "optim_result_surrogate_rev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim_result_surrogate_origin_rev = sum([sum(Xr[xtoc==ind][:,int(rev_list[ind])]) for ind in range(len(rev_list))])\n",
    "optim_result_surrogate_origin_rev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, there is no difference at all, because we generated the results the same way. Actually the question would be, why there was difference in the carbon case?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again comparison to original:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "orig_weights = np.ones(len(X))\n",
    "OrigProblemRev = BorealWeightedProblem(Xr,orig_weights)\n",
    "opt.solve(OrigProblemRev.model, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_res_values_rev = res_to_list(OrigProblemRev.model)\n",
    "optim_result_orig_rev = sum([Xr[ind,int(orig_res_values_rev[ind])] for ind in range(len(orig_res_values_rev))])\n",
    "optim_result_orig_rev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "(optim_result_orig_rev - optim_result_surrogate_origin_rev) / optim_result_orig_rev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time the difference is 1.3% which really is 4x bigger than with clustering build for the same objective. Still I don't consider this extremely alarming. This aspect is one great topic to be examined."
   ]
  }
 ],
 "metadata": {
  "git": {
   "suppress_outputs": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
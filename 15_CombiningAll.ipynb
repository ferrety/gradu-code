{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining all together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have all the pieces necessary to make implement the interactive optimization process using clustering as surrogates and different scalarization functions. Yeah."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    " %matplotlib inline\n",
    "import seaborn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from ASF import ASF\n",
    "from gradutil import *\n",
    "from pyomo.opt import SolverFactory\n",
    "seedn = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First lets take all the data in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "revenue, carbon, deadwood, ha = init_boreal()\n",
    "n_revenue = nan_to_bau(revenue)\n",
    "n_carbon= nan_to_bau(carbon)\n",
    "n_deadwood = nan_to_bau(deadwood)\n",
    "n_ha = nan_to_bau(ha)\n",
    "ide = ideal(False)\n",
    "nad = nadir(False)\n",
    "opt = SolverFactory('glpk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.concat((n_revenue, n_carbon, n_deadwood, n_ha), axis=1)\n",
    "x_stack = np.dstack((n_revenue, n_carbon, n_deadwood, n_ha))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize all the columns in 0-1 scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_revenue = new_normalize(n_revenue)\n",
    "norm_carbon = new_normalize(n_carbon)\n",
    "norm_deadwood = new_normalize(n_deadwood)\n",
    "norm_ha = new_normalize(n_ha)\n",
    "\n",
    "x_norm = np.concatenate((norm_revenue, norm_carbon, norm_deadwood, norm_ha), axis=1)\n",
    "x_norm_stack = np.dstack((norm_revenue, norm_carbon, norm_deadwood, norm_ha))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cluster the data to some clusters and calculate correponding weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "nclust1 = 200\n",
    "c, xtoc, dist = cluster(x_norm, nclust1, seedn, verbose=1)\n",
    "nvar = len(x_norm)\n",
    "w = np.array([sum(xtoc == i) for i in range(nclust1)])/nvar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate new cluster centers using average from normalized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_mean = np.array([x_norm_stack[xtoc == i].mean(axis=0) for i in range(nclust1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate new cluster centers using stand closest to the center of the cluster. This option could be more justified in the practical level, because we don't know so much about the forestry and features of forest stands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import euclidean\n",
    "c_close = np.array([x_norm_stack[min(np.array(range(len(xtoc)))[xtoc == i],\n",
    "                                     key=lambda index: euclidean(x_norm[index],\n",
    "                                                                 np.mean(x_norm[xtoc == i], axis=0)))]\n",
    "                    for i in range(nclust1)\n",
    "                    if sum(xtoc == i) > 0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate solution for some reference using the cluster centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref = np.array((ide[0], 0, 0, 0))\n",
    "mean_asf = ASF(ide, nad, ref, c_mean, weights=w, nvar=nvar)\n",
    "res_asf_mean = opt.solve(mean_asf.model)\n",
    "mean_stom = ASF(ide, nad, ref, c_mean, weights=w, nvar=nvar, scalarization='stom')\n",
    "res_stom_mean = opt.solve(mean_stom.model)\n",
    "mean_guess = ASF(ide, nad, ref, c_mean, weights=w, nvar=nvar, scalarization='guess')\n",
    "res_stom_mean = opt.solve(mean_guess.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "(model_to_real_values(x_stack, mean_asf.model, xtoc),\n",
    "model_to_real_values(x_stack, mean_stom.model, xtoc),\n",
    "model_to_real_values(x_stack, mean_guess.model, xtoc),\n",
    "ide)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate solution for some reference using the stands closest to the cluster center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref = np.array((ide[0], 0, 0, 0))\n",
    "close_asf = ASF(ide, nad, ref, c_close, weights=w, nvar=nvar)\n",
    "res_close = opt.solve(close_asf.model)\n",
    "close_stom = ASF(ide, nad, ref, c_close, weights=w, nvar=nvar, scalarization='stom')\n",
    "res_stom_close = opt.solve(close_stom.model)\n",
    "close_guess = ASF(ide, nad, ref, c_close, weights=w, nvar=nvar, scalarization='guess')\n",
    "res_stom_close = opt.solve(close_guess.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "(model_to_real_values(x_stack, close_asf.model, xtoc),\n",
    "model_to_real_values(x_stack, close_stom.model, xtoc),\n",
    "model_to_real_values(x_stack, close_guess.model, xtoc),\n",
    "ide)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref = np.array((0, ide[1], 0, 0))\n",
    "close_asf = ASF(ide, nad, ref, c_close, weights=w, nvar=nvar)\n",
    "res_close = opt.solve(close_asf.model)\n",
    "close_stom = ASF(ide, nad, ref, c_close, weights=w, nvar=nvar, scalarization='stom')\n",
    "res_stom_close = opt.solve(close_stom.model)\n",
    "close_guess = ASF(ide, nad, ref, c_close, weights=w, nvar=nvar, scalarization='guess')\n",
    "res_stom_close = opt.solve(close_guess.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "(model_to_real_values(x_stack, close_asf.model, xtoc),\n",
    "model_to_real_values(x_stack, close_stom.model, xtoc),\n",
    "model_to_real_values(x_stack, close_guess.model, xtoc),\n",
    "ide)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref = np.array((0, 0,ide[2], 0))\n",
    "close_asf = ASF(ide, nad, ref, c_close, weights=w, nvar=nvar)\n",
    "res_close = opt.solve(close_asf.model)\n",
    "close_stom = ASF(ide, nad, ref, c_close, weights=w, nvar=nvar, scalarization='stom')\n",
    "res_stom_close = opt.solve(close_stom.model)\n",
    "close_guess = ASF(ide, nad, ref, c_close, weights=w, nvar=nvar, scalarization='guess')\n",
    "res_stom_close = opt.solve(close_guess.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "(model_to_real_values(x_stack, close_asf.model, xtoc),\n",
    "model_to_real_values(x_stack, close_stom.model, xtoc),\n",
    "model_to_real_values(x_stack, close_guess.model, xtoc), \n",
    "ide)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref = np.array((0, 0, 0, ide[3]))\n",
    "close_asf = ASF(ide, nad, ref, c_close, weights=w, nvar=nvar)\n",
    "res_close = opt.solve(close_asf.model)\n",
    "close_stom = ASF(ide, nad, ref, c_close, weights=w, nvar=nvar, scalarization='stom')\n",
    "res_stom_close = opt.solve(close_stom.model)\n",
    "close_guess = ASF(ide, nad, ref, c_close, weights=w, nvar=nvar, scalarization='guess')\n",
    "res_stom_close = opt.solve(close_guess.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "(model_to_real_values(x_stack, close_asf.model, xtoc),\n",
    "model_to_real_values(x_stack, close_stom.model, xtoc),\n",
    "model_to_real_values(x_stack, close_guess.model, xtoc),\n",
    "ide)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It really looks like that the scalarizations are emphasizing the objective we are setting as the target. It looks fine then."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also can say that using the \"close\" values we get more averaged results, but anyway they are more justified than just the means of clusters."
   ]
  }
 ],
 "metadata": {
  "git": {
   "suppress_outputs": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering and Optimization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets form the clusters first using k-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    " %matplotlib inline\n",
    "import seaborn\n",
    "import matplotlib.pyplot as plt\n",
    "from kmeans import kmeans, randomsample\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "from BorealWeights import BorealWeightedProblem\n",
    "from pyomo.opt import SolverFactory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "seed = 2\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "data_dir = os.path.join(os.getcwd(), '../boreal_data')\n",
    "carbon = pd.read_csv(os.path.join(data_dir, 'Carbon_storage.csv'))\n",
    "X = carbon.values\n",
    "X[carbon.isnull()] = np.nanmin(carbon) - np.nanmax(carbon)\n",
    "randomcenters = randomsample(X, 50)\n",
    "centers, xtoc, dist = kmeans(X,\n",
    "                             randomcenters,\n",
    "                             delta=.00001,\n",
    "                             maxiter=100,\n",
    "                             metric='cosine',\n",
    "                             verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "C = centers.copy()\n",
    "weights = np.array([sum(xtoc==i) for i in range(0,len(C))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ClustProblem = BorealWeightedProblem(C,weights)\n",
    "opt = SolverFactory('glpk')\n",
    "res = opt.solve(ClustProblem.model, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def res_to_list(model):\n",
    "    resdict = model.x.get_values()\n",
    "    reslist = np.zeros(model.n.value)\n",
    "    for i,j in resdict.keys():\n",
    "        if resdict[i,j] == 1.:\n",
    "            reslist[i] = j\n",
    "    return reslist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "reslist = res_to_list(ClustProblem.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "optim_result_surrogate = sum([C[ind,int(reslist[ind])]*weights[ind] for ind in range(len(reslist))])\n",
    "optim_result_surrogate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is pretty close to the optimization values acquired by traditional optimization!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also check corresponding values using original values in clusters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim_result_surrogate_origin = sum([sum(X[xtoc==ind][:,int(reslist[ind])]) for ind in range(len(reslist))])\n",
    "optim_result_surrogate_origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(optim_result_surrogate - optim_result_surrogate_origin)/optim_result_surrogate_origin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relative error between surrogate result and surrogate result mapped back to original values is quite small"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare also to original optimization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "orig_weights = np.ones(len(X))\n",
    "OrigProblem = BorealWeightedProblem(X,orig_weights)\n",
    "opt.solve(OrigProblem.model, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_res_values = res_to_list(OrigProblem.model)\n",
    "optim_result_orig = sum([X[ind,int(orig_res_values[ind])] for ind in range(len(orig_res_values))])\n",
    "optim_result_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "(optim_result_orig - optim_result_surrogate_origin) / optim_result_orig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The difference is then about 3%, which isn't so bad. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step would be rethinkin the clustering:\n",
    "- what happens if we now use the same clustering to calculate f.ex. revenue values.?\n",
    "- do we use all the data values to create clusters?"
   ]
  }
 ],
 "metadata": {
  "git": {
   "suppress_outputs": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
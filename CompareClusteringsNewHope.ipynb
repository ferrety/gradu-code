{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to handle Nan-values so that the HA doesn't get marginalized?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It has been a problem this far, that the clustering doesn't work as desired, and the problem is now located in the procedure Nan-values have been handled in clustering. So we need a better way to do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    " %matplotlib inline\n",
    "import seaborn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from gradutil import *\n",
    "from pyomo.opt import SolverFactory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "seedn = 2\n",
    "opt = SolverFactory('glpk')\n",
    "solutions = real_solutions()\n",
    "revenue, carbon, deadwood, ha = init_boreal()\n",
    "x = np.concatenate((revenue, carbon, deadwood, ha), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set nan:s to smallest existing option"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first just try setting all nan:s to the smallest value in the corresponding column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_data = x.copy()\n",
    "inds = np.where(np.isnan(norm_data))\n",
    "norm_data[inds] = np.take(np.nanmin(norm_data, axis=0),inds[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then normalize all as before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_norm_x = normalize(norm_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "pylab.rcParams['figure.figsize'] = (15,12)\n",
    "\n",
    "def hist_plot_norm(data, ax, limits):\n",
    "    ax[0,0].hist(data[:, :7])\n",
    "    ax[0,0].axis(limits)\n",
    "    ax[0,0].set_title('Timber Harvest Revenues')\n",
    "\n",
    "    ax[0,1].hist(data[:, 7:14])\n",
    "    ax[0,1].axis(limits)\n",
    "    ax[0,1].set_title('Carbon storage')\n",
    "\n",
    "    ax[1,0].hist(data[:, 14:21])\n",
    "    ax[1,0].axis(limits)\n",
    "    ax[1,0].set_title('Deadwood')\n",
    "\n",
    "    ax[1,1].hist(data[:, 21:])\n",
    "    ax[1,1].axis(limits)\n",
    "    ax[1,1].set_title('Habitat availability')\n",
    "    return ax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = min_norm_x\n",
    "fig, ax = plt.subplots(2,2)\n",
    "limits = [.0, 1., 0, 30000]\n",
    "hist_plot_norm(data, ax, limits)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "nclust = 50\n",
    "optim_revenue50, optim_carbon50, optim_deadwood50, optim_ha50 = cNopt(x, min_norm_x, min_norm_x, opt, nclust, seedn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Relative differences to original values, 50 clusters')\n",
    "print(\"(i) Harvest revenues difference {:.3f}\".format((optim_revenue50-solutions['revenue'])/solutions['revenue']))\n",
    "print(\"(ii) Carbon storage {:.3f}\".format((optim_carbon50-solutions['carbon'])/solutions['carbon']))\n",
    "print(\"(iii) Deadwood index {:.3f}\".format((optim_deadwood50-solutions['deadwood'])/solutions['deadwood']))\n",
    "print(\"(iv) Combined Habitat {:.3f}\".format((optim_ha50-solutions['ha'])/solutions['ha']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it looks like this setting is not enough to drive optimization away from these points, and it doesn't tell anything about clustering. We need to adjust values for the optimization part, so we can know how the clustering goes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_nan_x = x.copy()\n",
    "inds = np.where(np.isnan(no_nan_x))\n",
    "no_nan_x[inds] = np.take(np.nanmin(no_nan_x, axis=0) - np.nanmax(no_nan_x, axis=0), inds[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is then great penalty for choosing the Nan values in optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "nclust = 50\n",
    "penalty_optim_revenue50, penalty_optim_carbon50, penalty_optim_deadwood50, penalty_optim_ha50 = cNopt(x, min_norm_x, no_nan_x, opt, nclust, seedn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Relative differences to original values, 50 clusters')\n",
    "print(\"(i) Harvest revenues difference {:.3f}\".format((penalty_optim_revenue50-solutions['revenue'])/solutions['revenue']))\n",
    "print(\"(ii) Carbon storage {:.3f}\".format((penalty_optim_carbon50-solutions['carbon'])/solutions['carbon']))\n",
    "print(\"(iii) Deadwood index {:.3f}\".format((penalty_optim_deadwood50-solutions['deadwood'])/solutions['deadwood']))\n",
    "print(\"(iv) Combined Habitat {:.3f}\".format((penalty_optim_ha50-solutions['ha'])/solutions['ha']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have optimization results and it looks like the clustering is not working. We need another paradigma to handle the Nan-values..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Give nan:s some penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_data = x.copy()\n",
    "inds = np.where(np.isnan(norm_data))\n",
    "norm_data[inds] = np.take((np.nanmin(norm_data, axis=0)-np.nanmax(norm_data, axis=0))/2,inds[1])\n",
    "penalty_norm_x = normalize(norm_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,2)\n",
    "limits = [.0, 1., 0, 30000]\n",
    "hist_plot_norm(penalty_norm_x, ax, limits)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "nclust = 50\n",
    "half_optim_revenue50, half_optim_carbon50, half_optim_deadwood50, half_optim_ha50 = cNopt(x, penalty_norm_x, no_nan_x, opt, nclust, seedn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Relative differences to original values, 50 clusters')\n",
    "print(\"(i) Harvest revenues difference {:.3f}\".format((half_optim_revenue50-solutions['revenue'])/solutions['revenue']))\n",
    "print(\"(ii) Carbon storage {:.3f}\".format((half_optim_carbon50-solutions['carbon'])/solutions['carbon']))\n",
    "print(\"(iii) Deadwood index {:.3f}\".format((half_optim_deadwood50-solutions['deadwood'])/solutions['deadwood']))\n",
    "print(\"(iv) Combined Habitat {:.3f}\".format((half_optim_ha50-solutions['ha'])/solutions['ha']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is not working either. Need something else."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Give nans ridiculous penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "norm_data = x.copy()\n",
    "inds = np.where(np.isnan(norm_data))\n",
    "norm_data[inds] = np.take((np.nanmin(norm_data, axis=0)-np.nanmax(norm_data, axis=0))*2,inds[1])\n",
    "ridiculous_norm_x = normalize(norm_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,2)\n",
    "limits = [.0, 1., 0, 30000]\n",
    "hist_plot_norm(ridiculous_norm_x, ax, limits)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "nclust = 50\n",
    "ridic_optim_revenue50, ridic_optim_carbon50, ridic_optim_deadwood50, ridic_optim_ha50 = cNopt(x, ridiculous_norm_x, no_nan_x, opt, nclust, seedn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Relative differences to original values, 50 clusters')\n",
    "print(\"(i) Harvest revenues difference {:.3f}\".format((ridic_optim_revenue50-solutions['revenue'])/solutions['revenue']))\n",
    "print(\"(ii) Carbon storage {:.3f}\".format((ridic_optim_carbon50-solutions['carbon'])/solutions['carbon']))\n",
    "print(\"(iii) Deadwood index {:.3f}\".format((ridic_optim_deadwood50-solutions['deadwood'])/solutions['deadwood']))\n",
    "print(\"(iv) Combined Habitat {:.3f}\".format((ridic_optim_ha50-solutions['ha'])/solutions['ha']))"
   ]
  }
 ],
 "metadata": {
  "git": {
   "suppress_outputs": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}